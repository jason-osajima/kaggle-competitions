{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "import random\n",
    "from datetime import date, datetime, timedelta\n",
    "import gc\n",
    "from io import StringIO\n",
    "\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAL_DTYPES={\"event_name_1\": \"category\", \"event_name_2\": \"category\", \"event_type_1\": \"category\", \n",
    "         \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int16\",\n",
    "        \"month\": \"int16\", \"year\": \"int16\", \"snap_CA\": \"float32\", 'snap_TX': 'float32', 'snap_WI': 'float32' }\n",
    "PRICE_DTYPES = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float32\" }\n",
    "\n",
    "BUCKET = 'dtci-dataplatform-telemetry-datsci-dev-bucket'\n",
    "S3_PATH = 'Jason/m5'\n",
    "CLIENT = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_start = 1500\n",
    "dataset_end = 1913\n",
    "nrows = 500\n",
    "\n",
    "numcols = [f\"d_{day}\" for day in range(dataset_start, dataset_end + 1)]\n",
    "catcols = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "keycols = ['id']\n",
    "dtype = {numcol:\"float32\" for numcol in numcols} \n",
    "dtype.update({col: \"category\" for col in catcols if col != \"id\"}) \n",
    "\n",
    "filename = 'sales_train_validation.csv'\n",
    "obj = CLIENT.get_object(Bucket = BUCKET, Key = os.path.join(S3_PATH, filename))\n",
    "df = pd.read_csv(obj['Body'], nrows = nrows, usecols = keycols + numcols, dtype = dtype)\n",
    "\n",
    "filename = 'sales_train_validation.csv'\n",
    "obj = CLIENT.get_object(Bucket = BUCKET, Key = os.path.join(S3_PATH, filename))\n",
    "cat_df = pd.read_csv(obj['Body'], nrows = nrows, usecols = keycols + catcols, dtype = dtype)\n",
    "\n",
    "filename = 'calendar.csv'\n",
    "obj = CLIENT.get_object(Bucket = BUCKET, Key = os.path.join(S3_PATH, filename))\n",
    "cal =  pd.read_csv(obj['Body'], dtype = CAL_DTYPES)\n",
    "cal[\"date\"] = pd.to_datetime(cal[\"date\"])\n",
    "for col, col_dtype in CAL_DTYPES.items():\n",
    "    if col_dtype == \"category\":\n",
    "        cal[col] = cal[col].cat.codes.astype(\"int16\")\n",
    "        cal[col] -= cal[col].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sell_prices.csv'\n",
    "obj = CLIENT.get_object(Bucket = BUCKET, Key = os.path.join(S3_PATH, filename))\n",
    "prices =  pd.read_csv(obj['Body'], dtype = PRICE_DTYPES)\n",
    "\n",
    "for col, col_dtype in PRICE_DTYPES.items():\n",
    "    if col_dtype == \"category\":\n",
    "        prices[col] = prices[col].cat.codes.astype(\"int16\")\n",
    "        prices[col] -= prices[col].min()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'store_id': 'category',\n",
       " 'item_id': 'category',\n",
       " 'wm_yr_wk': 'int16',\n",
       " 'sell_price': 'float32'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRICE_DTYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11325</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11326</td>\n",
       "      <td>9.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11327</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11328</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11329</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_id  item_id  wm_yr_wk  sell_price\n",
       "0         0        0     11325        9.58\n",
       "1         0        0     11326        9.58\n",
       "2         0        0     11327        8.26\n",
       "3         0        0     11328        8.26\n",
       "4         0        0     11329        8.26"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, end, periods, freq='D'):\n",
    "    \"\"\"\n",
    "    Returns subset of dataframe sliced by a given range of dates (start : start + periods)\n",
    "    \"\"\"\n",
    "    return df[pd.date_range(end=end, periods=periods, freq=freq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index to id\n",
    "df = df.set_index('id')\n",
    "# Map codes to actual dates\n",
    "d_to_date = dict(zip(cal['d'], cal['date']))\n",
    "date_to_d = dict(zip(cal['date'], cal['d']))\n",
    "df = df.rename(columns=d_to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_start = [1858, 1851, 1844, 1837, 1830, 1823, 1816]\n",
    "valid_y_start = 1886\n",
    "test_y_start = 1914\n",
    "\n",
    "# convert to datetime\n",
    "train_y_start = [d_to_date['d_{}'.format(integer_date)] for integer_date in train_y_start]\n",
    "valid_y_start = d_to_date['d_{}'.format(valid_y_start)]\n",
    "test_y_start = d_to_date['d_{}'.format(test_y_start)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, y_start, is_train = True):\n",
    "    # the X_start is 1 day before y_start\n",
    "    X_start = y_start - pd.Timedelta(days=1)\n",
    "    \n",
    "    X = {}\n",
    "    \n",
    "    for i in [1, 3, 7, 14, 30, 60, 140]:\n",
    "        # aggregate total\n",
    "        X['agg_sales_{}_days'.format(i)] = get_timespan(df, X_start, i).sum(axis=1)\n",
    "        \n",
    "        # diff mean, exp decay, mean, median, min, max, std\n",
    "        tmp = get_timespan(df, X_start, i)\n",
    "        X['diff_mean_sales_{}_days'.format(i)] = tmp.diff(axis=1).mean(axis=1).values\n",
    "        X['exp_decay_sales_{}_days'.format(i)] = (tmp * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "        X['mean_sales_{}_days'.format(i)] = tmp.mean(axis=1).values\n",
    "        X['median_{}_days'.format(i)] = tmp.median(axis=1).values\n",
    "        X['min_{}_days'.format(i)] = tmp.min(axis=1).values\n",
    "        X['max_{}_days'.format(i)] = tmp.max(axis=1).values\n",
    "        X['std_{}_days'.format(i)] = tmp.std(axis=1).values\n",
    "        \n",
    "        # diff mean, exp decay, mean, median, min, max, std lagged by 1 week\n",
    "        tmp = get_timespan(df, X_start - pd.Timedelta(days = 7), i)\n",
    "        X['diff_mean_sales_1weeklag_{}_days'.format(i)] = tmp.diff(axis=1).mean(axis=1).values\n",
    "        X['exp_decay_sales_1weeklag_{}_days'.format(i)] = (tmp * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "        X['mean_sales_1weeklag_{}_days'.format(i)] = tmp.mean(axis=1).values\n",
    "        X['median_1weeklag_{}_days'.format(i)] = tmp.median(axis=1).values\n",
    "        X['min_1weeklag_{}_days'.format(i)] = tmp.min(axis=1).values\n",
    "        X['max_1weeklag_{}_days'.format(i)] = tmp.max(axis=1).values\n",
    "        X['std_1weeklag_{}_days'.format(i)] = tmp.std(axis=1).values\n",
    "        \n",
    "        # mean + exponential decay number of sales for days when there was at least one sale\n",
    "        tmp1 = get_timespan(df, X_start, i)\n",
    "        tmp2 = (get_timespan(df, X_start, i) > 0) * 1\n",
    "        X['mean_nonzero_sales_{}_days'.format(i)] = (tmp1 * tmp2.replace(0, np.nan)).mean(axis=1).values\n",
    "        X['exp_decay_nonzero_sales_{}_days'.format(i)] = (tmp1 * tmp2.replace(0, np.nan) * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "        \n",
    "        # mean + exponential decay number of days when there wasn't a sale\n",
    "        X['mean_number_of_days_with_no_sales_{}_days'.format(i)] = (1 - tmp2).mean(axis=1).values\n",
    "        X['exp_decay_number_of_days_with_no_sales_{}_days'.format(i)] = ((1 - tmp2) * np.power(0.9, np.arange(i)[::-1])).sum(axis=1).values\n",
    "        \n",
    "        # last sale day\n",
    "        tmp = get_timespan(df, X_start, i)\n",
    "        X['has_sale_in_past_{}_days'.format(i)] = (tmp > 0).sum(axis=1).values\n",
    "        X['days_since_last_sale_{}_days'] = i - ((tmp > 0) * np.arange(i)).max(axis=1).values # if no sale in the past i days, return i\n",
    "        X['weighted_days_since_last_sale_{}_days'] = ((tmp > 0) * np.arange(i, 0, -1)).max(axis=1).values\n",
    "    \n",
    "    for i in range(1, 16):\n",
    "        # actual sales\n",
    "        X['actual_number_of_sales_{}_days'.format(i)] = get_timespan(df, X_start - pd.Timedelta(days=i), 1).values.ravel()\n",
    "    \n",
    "    for i in range(7):\n",
    "        X['mean_DOW_{}_past_4_weeks'.format(i)] = get_timespan(df, X_start - pd.Timedelta(days=28-i), 4, freq='7D').mean(axis=1).values\n",
    "        X['mean_DOW_{}_past_20_weeks'.format(i)] = get_timespan(df, X_start - pd.Timedelta(days=140-i), 20, freq='7D').mean(axis=1).values\n",
    "    \n",
    "    X = pd.DataFrame(X)\n",
    "    \n",
    "    if is_train:\n",
    "        y = df[\n",
    "            pd.date_range(y_start, periods=28)\n",
    "        ].values\n",
    "        return X, y\n",
    "    \n",
    "    else:\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, y_1 = [], []\n",
    "for y_start in train_y_start:\n",
    "    X_tmp, y_tmp = prepare_dataset(df, y_start)\n",
    "    X_1.append(X_tmp)\n",
    "    y_1.append(y_tmp)\n",
    "\n",
    "X_train = pd.concat(X_1, axis=0)\n",
    "y_train = np.concatenate(y_1, axis=0)\n",
    "\n",
    "del X_1, y_1; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = prepare_dataset(df, valid_y_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = prepare_dataset(df, test_y_start, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "Train one model for each day in y (28 models total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': 80,\n",
    "    'objective': 'poisson',\n",
    "    'min_data_in_leaf': 200,\n",
    "    'learning_rate': 0.02,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'rmse',\n",
    "    'num_threads': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 10000\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "\n",
    "# placeholder for categorical variables\n",
    "cate_vars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(28):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Instantiate Dataset\n",
    "    dtrain = lgb.Dataset(X_train.values, label=y_train[:, i], categorical_feature=cate_vars)\n",
    "    dval = lgb.Dataset(X_val.values, label=y_val[:, i], reference=dtrain, categorical_feature=cate_vars)\n",
    "    \n",
    "    # Train Model\n",
    "    bst = lgb.train(params, dtrain, num_boost_round=MAX_ROUNDS, \n",
    "                    valid_sets=[dtrain, dval], early_stopping_rounds=MAX_ROUNDS, verbose_eval=MAX_ROUNDS)\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).transpose()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=np.array(test_pred).transpose(),  index=X_test.index)\n",
    "submission.columns = ['F{}'.format(i + 1) for i in submission.columns.values]\n",
    "submission.reset_index(inplace=True)\n",
    "\n",
    "# dummy data for evaluation\n",
    "submission_eval = submission.copy()\n",
    "submission_eval[\"id\"] = submission_eval[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "submission = pd.concat([submission, submission_eval], axis=0, sort=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'submission_sequential_lgbm_{}.csv'.format(date.today().strftime('%m%d_%h'))\n",
    "csv_buffer = StringIO()\n",
    "submission.to_csv(csv_buffer, index=False)\n",
    "s3_object = boto3.resource('s3').Object(BUCKET, os.path.join(S3_PATH, 'submissions', filename))\n",
    "s3_object.put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
